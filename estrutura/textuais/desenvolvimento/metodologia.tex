% METODOLOGIA------------------------------------------------------------------

\chapter{Metodologia}
\label{chap:metodologia}

A metodologia do projeto consiste das seguintes etapas:

\begin{enumerate}
\item Revisão da literatura;
\item Definição e obtenção da base de vídeos
\item Definição dos algoritmos;
\item Implementação dos algoritmos; 
\item Definição do método de comparação;
\item Implementação do método de comparação;
\item Validação das implementações;
\item Definição dos experimentos;
\item Experimentos;
	\begin{enumerate}
		\item Compilação de uma nova base de vídeos;
        \item Geração dos vídeos com distorções;
        \item Geração da assinatura para todos os vídeos;
        \item Aplicação do método de comparação;
			% Especificações dos vídeos que serão utilizados
			% Dimensão, duração, taxa de frames, conteúdo dos videos, extensão (compressão), vídeos problemáticos
	\end{enumerate}
\item Análise dos resultados;
% \item Conclusão
\end{enumerate}

\section{Revisão da Literatura}

Foi realizada uma revisão da literatura pertinente à pesquisa. Este método de revisão da literatura foi escolhido pois define formas de identificar, interpretar e avaliar pesquisas disponíveis coerentes com o tema. 

Além de artigos recentes relacionados à área, as referências de \citeauthor{sylvio2015} também foram utilizadas na revisão e passaram pelo processo de filtragem, uma vez que este trabalho baseia-se no de \citeauthor{sylvio2015}.

\subsection{Definições}

O primeiro passo da revisão é a definição das perguntas que devem ser respondidas, das palavras-chave a serem utilizadas e dos critérios de exclusão de artigos. O intuito da revisão é definido a seguir:

\begin{itemize}
\item encontrar algoritmos para tratar diferentes problemas relacionados à descrição de vídeos e compreender seu funcionamento;
\item encontrar métodos de \textit{matching} de descritores;
\item encontrar e compilar uma base de vídeos para realização dos testes;
\end{itemize}

Além das referências de \citeauthor{sylvio2015}, foram escolhidos repositórios em português e em inglês para a busca das palavras-chave. Os repositórios estão definidos na tabela~\ref{tabela:listarepositorios} enquanto as palavras-chave na tabela \ref{tabela:palavraschave}.

\begin{table}[h]
\resizebox{\textwidth}{!}{
\begin{tabular}{|l|l|l|}
	\hline
    Língua & Repositórios & Endereço \\
    \hline
    \multirow{4}{*}{Inglês} & IEEE & \url{http://ieeexplore.ieee.org/Xplore/home.jsp} \\
    & ScienceDirect & \url{http://www.sciencedirect.com/} \\
    & ACM & \url{http://dl.acm.org/} \\
    & Google Scholar & \url{https://scholar.google.com.br/} \\
    \hline
    \multirow{2}{*}{Português} & Periódico CAPES & \url{http://www-periodicos-capes-gov-br.ez48.periodicos.capes.gov.br} \\
    & SciELO & \url{http://www.scielo.org} \\
    \hline
\end{tabular}
}
\caption[Lista de repositórios utilizados]{Lista de repositórios utilizados.}
\label{tabela:listarepositorios}
\end{table}

\begin{table}[h]
\resizebox{\textwidth}{!}{
\begin{tabular}{|l|l|}
\hline
Português & Inglês \\
\hline
Detecção de cópia baseada em conteúdo & Content-Based Video Copy Detection\\
\hline
Descritor de vídeo & Video fingerprint \\
\hline
Detecção de cópia de video & video copy detection \\
\hline
\end{tabular}
}
\caption{Palavras-chave utilizadas na revisão sistemática.}
\label{tabela:palavraschave}
\end{table}


Para auxiliar na indexação dos artigos achados e na sua utilização como base para este trabalho, os artigos foram divididos em categorias, como mostra a tabela \ref{tabela:categoriaartigos}.

\begin{table}[h]
\resizebox{\textwidth}{!}{
	\begin{tabular}{|l|l|l|}
    \hline
	& Categoria & Descrição \\
    \hline
    1 & Descritores Globais & Algoritmos que produzem descritores baseados em características globais de um vídeo \\
    \hline
    2 & Descritores Locais & Algoritmos que produzem descritores baseados em características locais de um vídeo \\
    \hline
    3 & Comparação de Descritores & Métodos para comparação de descritores \\
    \hline
	\end{tabular}
}
    \caption{Categorização dos artigos.}
    \label{tabela:categoriaartigos}
\end{table}

\section{Definição e Obtenção da Base de Vídeos}

Foi escolhida a base UCF50 - Action Recognition Data Set \citeauthor{reddy2013recognizing} e embora seja utilizada para reconhecimento de movimento humano baseado em ações, como por exemplo ciclismo, natação, caminhada com o cachorro, TaiChi, etc., os motivos para sua escolha foram a quantidade de vídeos e sua licença de livre utilização. 

Do total de 6.681 itens, foram selecionados 1.264, pois os vídeos estavam fragmentados em diversas cenas, ou seja, apenas uma cena de cada vídeo foi utilizada. Cada cena tem uma duração média de 3 a 9 segundos.

Para cada vídeo selecionado foram aplicadas 14 distorções, totalizando 18.960 itens, sendo destes, 17.696 vídeos resultantes das distorções.

[escrever das 14 distorções]

\section{Definição e implementação dos algoritmos}

Como este trabalho visa continuar a pesquisa em descritores de vídeo baseando-se em \citeauthor{sylvio2015}, os primeiros algoritmos estudados e implementados são os três algoritmos já implementados por ele, descritos nas Seções \ref{sec:med_ordinal}, \ref{sec:gradientes} e \ref{sec:framediff}.

Embora \citeauthor{sylvio2015} tenha optado por comparar apenas algoritmos de descrição global, devido a sua simplicidade de implementação, neste trabalho serão utilizados tanto descritores locais quanto globais.

POR QUE DOS OUTROS TRÊS ALGORITMOS?
[sao recentes e locais]


Foi escolhida a linguagem Python (versão 2.7.12) para a implementação dos algoritmos por ser multiplataforma e  por sua simplicidade na integração com bibliotecas de alta-performance implementadas em linguagens de baixo nível (C). Isto foi importante pois serão utilizadas as bibliotecas \textit{OpenCV} (versão 3.0.0) e \textit{NumPy} (versão 1.12.1) para manipulação e operação de imagens.

Para a compilação da base de vídeos foi utilizada a biblioteca MagicImage (versão 7.0.7-8-Q16-x64 - Windows), que incluí os programas \textit{convert} e \textit{ffmpeg}, utilizados para conversão de formatos, aplicação de distorções e transformações de vídeo e imagem respectivamente.

\section{Definição e Implementação do método de comparação}




pegar base de assinaturas distrocidas, e para cada distorçao, calcular a distancia para todas as assinaturas originais

pegar as duas menores distancias para cada distorçao de cada vídeo

se a dif do primeiro colocado (primera distancia) for diferente o suficiente para o segundo colocado , entao podemos assumir (podemos?) que encontramos a assinatura do vídeo original

EMBASAR ESSAS PARADAS LOUCAS

\section{Validação das implementações}

Antes de realizar-se qualquer experimento, é necessário que os algoritmos implementados passem por uma etapa de validação que consiste em comparar seus resultados com os dos artigos de base. Para isso serão revisados os artigos dos quais os algoritmos foram retirados, além de códigos disponibilizados através destes trabalhos.

A validação ocorrerá em duas etapas:

\begin{enumerate}
\item teste de software;
\item comparação das saídas dos algoritmos implementados para o trabalho e as implementações originais, dada a mesma entrada.
\end{enumerate}

