% METODOLOGIA------------------------------------------------------------------

\chapter{Metodologia}
\label{chap:metodologia}

% LEMBRAR DE NÃO FALAR DO SILVIO AQUI

A metodologia empregada neste trabalho está organizada nos seguintes passos principais:

\begin{description}
\item[Etapa 1] Aquisição da base de vídeos UCF50 - Action Recognition Data Set \citeauthor{reddy2013recognizing}.
\item[Etapa 2] Aplicação das 14 distorções descritar na Seção~/\ref{sec:ataques} sobre a base.
\item[Etapa 3] Geração das assinaturas utilizando os algoritmos baseados em diferença de quadro, gradientes, medida ordinal, quadros de cena e wavelets, descritos no Capítulo~\ref{chap:revisao}.
\item[Etapa 4] Realização do procedimento de comparação de um conjunto de treinamento das assinaturas, a fim de definir um limiar para classificação.
\item[Etapa 5] Realização do procedimento de comparação de um conjunto de testes das assinaturas, a partir dos limiares obtidos na Etapa 4.
\item[Etapa 5] Análise comparativa dos resultados obtidos a partir da Etapas 4. Os resultados desta etapa serão discutidos em detalhes no próximo capítulo.
\end{description}

As seções a seguir detalham como esses passos serão realizados.

\section{Definição e Obtenção da Base de Vídeos}
\label{sec:database}

Foi escolhida a base UCF50 - Action Recognition Data Set \citeauthor{reddy2013recognizing}, que é comumente utilizada para em projetos de reconhecimento de movimento humano e está segmentada em 50 categorias diferentes que representam ações do quotidiano, como por exemplo ciclismo, natação, caminhada com o cachorro, TaiChi, etc. Dentro de cada categoria, os vídeos há pelo menos 4 vídeos pertencentes a uma mesma gravação, apresentando assim o mesmo os mesmos personagens, fundo e ponto de vista. A fim de reduzir o número de vídeos que apresentam o mesmo conteúdo, foram selecionados apenas o primeiro vídeo de cada grupo.

A base original é composta de 6.681 vídeos com duração média entre 3 a 9 segundos e após a seleção descrita no parágrafo anterior, restaram 1.264 vídeos. 

os motivos para sua escolha foram a quantidade de vídeos e sua licença de livre utilização. 

Do total de 6.681 itens, foram selecionados 1.264, pois os vídeos estavam fragmentados em diversas cenas, ou seja, apenas uma cena de cada vídeo foi utilizada. Cada cena tem uma duração média de 3 a 9 segundos.

Para cada vídeo selecionado foram aplicadas as distorções descritas em \ref{sec:distorcoes}, totalizando 18.960 itens, sendo destes, 17.696 vídeos resultantes das distorções.

\section{Definição e implementação dos algoritmos}

\textbf{[TODO]}


Foi escolhida a linguagem Python (versão 2.7.12) para a implementação dos algoritmos por ser multiplataforma e  por sua simplicidade na integração com bibliotecas de alta-performance implementadas em linguagens de baixo nível (C). Isto foi importante pois serão utilizadas as bibliotecas \textit{OpenCV} (versão 3.0.0) e \textit{NumPy} (versão 1.12.1) para manipulação e operação de imagens.

Para a compilação da base de vídeos foi utilizada a biblioteca MagicImage (versão 7.0.7-8-Q16-x64 - Windows), que incluí os programas \textit{convert} e \textit{ffmpeg}, utilizados para conversão de formatos, aplicação de distorções e transformações de vídeo e imagem respectivamente.

\section{Definição e Implementação do método de comparação}


\textbf{[EM DESENVOLVIMENTO]}

% pegar base de assinaturas distrocidas, e para cada distorçao, calcular a distancia para todas as assinaturas originais

% pegar as duas menores distancias para cada distorçao de cada vídeo

% se a dif do primeiro colocado (primera distancia) for diferente o suficiente para o segundo colocado , entao podemos assumir (podemos?) que encontramos a assinatura do vídeo original

% EMBASAR ESSAS PARADAS LOUCAS

\section{Validação das implementações}

Antes de realizar-se qualquer experimento, é necessário que os algoritmos implementados passem por uma etapa de validação que consiste em comparar seus resultados com os dos artigos de base. Para isso serão revisados os artigos dos quais os algoritmos foram retirados, além de códigos disponibilizados através destes trabalhos.

A validação ocorrerá em duas etapas:

\begin{enumerate}
\item teste de software;
\item comparação das saídas dos algoritmos implementados para o trabalho e as implementações originais, dada a mesma entrada.
\end{enumerate}

\section{Definição dos Experimentos}
\label{sec:definicaoexperimentos}